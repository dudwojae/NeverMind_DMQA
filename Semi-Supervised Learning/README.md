## Semi-Supervised Learning
Key Summary and Description of Paper on Semi-Supervised Learning

* 2022-08-05
  * Jihyun Kim / Regularization With Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning [[paper]](https://proceedings.neurips.cc/paper/2016/hash/30ef30b64204a3088a26bc2e6ecf7602-Abstract.html)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/Semi-Supervised%20Learning/20220805/%5B20220805%5DRegularization_With_Stochastic_Transformations_and_Perturbations_for_Deep_Semi_Supervised_Learning%20(NeurIPS%202016).pdf)
  * Hyeonji Kim / Temporal Ensembling for Semi-Supervised Learning [[paper]](https://arxiv.org/abs/1610.02242)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/Semi-Supervised%20Learning/20220805/%5B20220805%5DTemporal%20Ensembling%20for%20Semi-Supervised%20Learning%20(ICLR%202017).pdf)
  
* 2022-08-12
  * Yongwon Jo / Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning [[paper]](https://ieeexplore.ieee.org/abstract/document/8417973)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/Semi-Supervised%20Learning/20220812/%5B20220812%5DVirtual%20Adversarial%20Training.pdf)
  * Jinyong Jeong / Mean Teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results [[paper]](https://proceedings.neurips.cc/paper/2017/hash/68053af2923e00204c3ca7c6a3150cf7-Abstract.html)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/Semi-Supervised%20Learning/20220812/%5B20220812%5DMean%20teachers%20are%20better%20role%20models%20-%20Weight-averaged%20consistency%20targets%20improve%20semi-supervised%20deep%20learning%20results%20(NeurIPS%202017).pdf)

* 2022-08-19
  * Eunji Koh / There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average [[paper]](https://arxiv.org/abs/1806.05594)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/Semi-Supervised%20Learning/20220819/%5B20220819%5D%20There%20Are%20Many%20Consistent%20Explanations%20of%20Unlabeled%20Data_%20Why%20You%20Should%20Average.pdf)
  * Sangmin Kim / MixMatch: A Holistic Approach to Semi-Supervised Learning [[paper]](https://proceedings.neurips.cc/paper/2019/hash/1cd138d0499a68f4bb72bee04bbec2d7-Abstract.html)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/Semi-Supervised%20Learning/20220819/%5B20220819%5D%20MixMatch-A%20Holistic%20Approach%20to%20Semi-Supervised%20Learning.pdf)

* 2022-08-26
  * Leekyung yoo / FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence [[paper]](https://proceedings.neurips.cc/paper/2020/hash/06964dce9addb1c5cb5d6e3d9838f733-Abstract.html)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/Semi-Supervised%20Learning/20220826/%5B20220826%5D%20FixMatch-Simplifying%20Semi-Supervised%20Learning%20with%20Consistency%20and%20Confidence.pdf)
  * Jongkook Heo / ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring [[paper]](https://arxiv.org/abs/1911.09785)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/Semi-Supervised%20Learning/20220826/%5B20220826%5DReMixMatch-Semi%20Supervised%20Learning%20with%20Distribution%20Alignment%20and%20Augmentation%20Anchoring.pdf)

* 2022-09-23
  * Insung Baek / Semi-Supervised Learning under Class Distribution Mismatch [[paper]](https://ojs.aaai.org/index.php/AAAI/article/view/5763)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/Semi-Supervised%20Learning/20220923/%5B20220923%5DSemi-supervised%20learning%20under%20class%20distribution%20mismatch.pdf)
  * Goeun Chae / Realistic Evaluation of Deep Semi-Supervised Learning Algorithms [[paper]](https://proceedings.neurips.cc/paper/2018/hash/c1fea270c48e8079d8ddf7d06d26ab52-Abstract.html)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/Semi-Supervised%20Learning/20220923/%5B20220923%5DRealistic%20Evaluation%20of%20Deep%20Semi-Supervised%20Learning%20Algorithms.pdf)
  
* 2022-09-30
  * Hansam Cho / Multi-task Curriculum Framework for Open-Set Semi-supervised Learning [[paper]](https://link.springer.com/chapter/10.1007/978-3-030-58610-2_26)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/Semi-Supervised%20Learning/20220930/%5B20220930%5DMulti-Task%20Curriculum%20Framework%20for%20Open-Set%20Semi-Supervised%20Learning.pdf)
  * Jinsoo Bae / Safe Deep Semi-Supervised Learning for Unseen-Class Unlabeled Data [[paper]](https://proceedings.mlr.press/v119/guo20i.html)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/Semi-Supervised%20Learning/20220930/%5B20220930%5DSafe%20Deep%20Semi-Supervised%20Learning%20for%20Unseen-Class%20Unlabeled%20Data.pdf)

* 2022-10-07
  * Jungin Kim / PUMAD: PU Metric Learning for Anomaly Detection [[paper]](https://www.sciencedirect.com/science/article/pii/S0020025520302012)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/Semi-Supervised%20Learning/20221007/%5B20221007%5DPUMAD_PU%20Metric%20learning%20for%20anomaly%20detection%20(Information%20Sciences%2C%202020).pdf)
  * Saerin Lim / OpenMatch: Open-Set Semi-Supervised Learning with Open-Set Consistency Regularization [[paper]](https://proceedings.neurips.cc/paper/2021/hash/da11e8cd1811acb79ccf0fd62cd58f86-Abstract.html)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/Semi-Supervised%20Learning/20221007/%5B20221007%5DOpenMatch%20-%20Open-set%20Consistency%20Regularization%20for%20Semi-supervised%20Learning%20with%20Outliers.pdf)
  
* 2022-10-28
  * Young Jae Lee /
  * Jaehoon Kim / 
  * Jinhyeok Park /
